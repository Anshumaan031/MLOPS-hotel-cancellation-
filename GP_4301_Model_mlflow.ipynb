{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GLjuo97KNd3O"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os, shutil\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, roc_auc_score, make_scorer\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from hyperopt import hp, tpe, Trials, fmin, STATUS_OK\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KG2VI-4-REWa",
    "outputId": "0d5cd96c-9e9e-4f4b-d931-d2895f600ab3"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZKU76pFVRdAo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118660, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booking_id</th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>...</th>\n",
       "      <th>company</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>booking_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2014-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>737</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2013-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-06-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   booking_id         hotel  is_canceled  lead_time  arrival_date_year  \\\n",
       "0           0  Resort Hotel            0        342               2015   \n",
       "1           1  Resort Hotel            0        737               2015   \n",
       "2           2  Resort Hotel            0          7               2015   \n",
       "3           3  Resort Hotel            0         13               2015   \n",
       "4           4  Resort Hotel            0         14               2015   \n",
       "\n",
       "  arrival_date_month  arrival_date_week_number  arrival_date_day_of_month  \\\n",
       "0               July                        27                          1   \n",
       "1               July                        27                          1   \n",
       "2               July                        27                          1   \n",
       "3               July                        27                          1   \n",
       "4               July                        27                          1   \n",
       "\n",
       "   stays_in_weekend_nights  stays_in_week_nights  ...  company  \\\n",
       "0                        0                     0  ...      NaN   \n",
       "1                        0                     0  ...      NaN   \n",
       "2                        0                     1  ...      NaN   \n",
       "3                        0                     1  ...      NaN   \n",
       "4                        0                     2  ...      NaN   \n",
       "\n",
       "   days_in_waiting_list  customer_type   adr required_car_parking_spaces  \\\n",
       "0                     0      Transient   0.0                           0   \n",
       "1                     0      Transient   0.0                           0   \n",
       "2                     0      Transient  75.0                           0   \n",
       "3                     0      Transient  75.0                           0   \n",
       "4                     0      Transient  98.0                           0   \n",
       "\n",
       "  total_of_special_requests reservation_status  reservation_status_date  \\\n",
       "0                         0          Check-Out               2015-07-01   \n",
       "1                         0          Check-Out               2015-07-01   \n",
       "2                         0          Check-Out               2015-07-02   \n",
       "3                         0          Check-Out               2015-07-02   \n",
       "4                         1          Check-Out               2015-07-03   \n",
       "\n",
       "   arrival_date  booking_date  \n",
       "0    2015-07-01    2014-07-24  \n",
       "1    2015-07-01    2013-06-24  \n",
       "2    2015-07-01    2015-06-24  \n",
       "3    2015-07-01    2015-06-18  \n",
       "4    2015-07-01    2015-06-17  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_bookings_train_data = pd.read_csv('hotel_bookings_training.csv')\n",
    "print(hotel_bookings_train_data.shape)\n",
    "hotel_bookings_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "booking_id                             0\n",
       "hotel                                  0\n",
       "is_canceled                            0\n",
       "lead_time                              0\n",
       "arrival_date_year                      0\n",
       "arrival_date_month                     0\n",
       "arrival_date_week_number               0\n",
       "arrival_date_day_of_month              0\n",
       "stays_in_weekend_nights                0\n",
       "stays_in_week_nights                   0\n",
       "adults                                 0\n",
       "children                               4\n",
       "babies                                 0\n",
       "meal                                   0\n",
       "country                              488\n",
       "market_segment                         0\n",
       "distribution_channel                   0\n",
       "is_repeated_guest                      0\n",
       "previous_cancellations                 0\n",
       "previous_bookings_not_canceled         0\n",
       "reserved_room_type                     0\n",
       "assigned_room_type                     0\n",
       "booking_changes                        0\n",
       "deposit_type                           0\n",
       "agent                              16180\n",
       "company                           111905\n",
       "days_in_waiting_list                   0\n",
       "customer_type                          0\n",
       "adr                                    0\n",
       "required_car_parking_spaces            0\n",
       "total_of_special_requests              0\n",
       "reservation_status                     0\n",
       "reservation_status_date                0\n",
       "arrival_date                           0\n",
       "booking_date                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_bookings_train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_bookings_train_data['agent'].fillna(0, inplace=True) # added extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3pYU8_9lR8EV"
   },
   "outputs": [],
   "source": [
    "class CustomPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy() \n",
    "\n",
    "        X = X.drop(X.columns[0], axis=1)\n",
    "        X.fillna(-1, inplace=True)\n",
    "        filter = (X['children'] == 0) & (X['adults'] == 0) & (X['babies'] == 0)\n",
    "        X = X[~filter]\n",
    "        useless_col = ['days_in_waiting_list', 'arrival_date_year', 'assigned_room_type', 'booking_changes',\n",
    "                       'reservation_status', 'country', 'days_in_waiting_list']\n",
    "        X.drop(useless_col, axis=1, inplace=True)\n",
    "        X[\"arrival_date\"] = pd.to_datetime(X[\"arrival_date\"])\n",
    "        X[\"booking_date\"] = pd.to_datetime(X[\"booking_date\"])\n",
    "\n",
    "        cat_cols = [col for col in X.columns if X[col].dtype == 'O']\n",
    "        cat_df = X[cat_cols]\n",
    "\n",
    "        if 'reservation_status_date' in cat_df:\n",
    "            cat_df['reservation_status_date'] = pd.to_datetime(cat_df['reservation_status_date'])\n",
    "            cat_df['year'] = cat_df['reservation_status_date'].dt.year\n",
    "            cat_df['month'] = cat_df['reservation_status_date'].dt.month\n",
    "            cat_df['day'] = cat_df['reservation_status_date'].dt.day\n",
    "            cat_df.drop(['reservation_status_date', 'arrival_date_month'], axis=1, inplace=True)\n",
    "\n",
    "        mappings = {\n",
    "            'hotel': {'Resort Hotel': 0, 'City Hotel': 1},\n",
    "            'meal': {'BB': 0, 'FB': 1, 'HB': 2, 'SC': 3, 'Undefined': 4},\n",
    "            'market_segment': {'Direct': 0, 'Corporate': 1, 'Online TA': 2, 'Offline TA/TO': 3,\n",
    "                               'Complementary': 4, 'Groups': 5, 'Undefined': 6, 'Aviation': 7},\n",
    "            'distribution_channel': {'Direct': 0, 'Corporate': 1, 'TA/TO': 2, 'Undefined': 3,\n",
    "                                     'GDS': 4},\n",
    "            'reserved_room_type': {'C': 0, 'A': 1, 'D': 2, 'E': 3, 'G': 4, 'F': 5, 'H': 6,\n",
    "                                   'L': 7, 'B': 8},\n",
    "            'deposit_type': {'No Deposit': 0, 'Refundable': 1, 'Non Refund': 3},\n",
    "            'customer_type': {'Transient': 0, 'Contract': 1, 'Transient-Party': 2, 'Group': 3},\n",
    "            'year': {2015: 0, 2014: 1, 2016: 2, 2017: 3}\n",
    "        }\n",
    "\n",
    "        for col, mapping in mappings.items():\n",
    "            if col in cat_df:\n",
    "                cat_df[col] = cat_df[col].map(mapping)\n",
    "                cat_df[col] = cat_df[col].fillna(-1)\n",
    "\n",
    "        num_df = X.select_dtypes(include=['int64', 'float64'])\n",
    "        #num_df.drop('is_canceled', axis=1, inplace=True)\n",
    "\n",
    "        for col in ['lead_time', 'arrival_date_week_number', 'arrival_date_day_of_month', 'agent', 'adr']:\n",
    "            if col in num_df:\n",
    "                num_df[col] = np.log(num_df[col] + 1)\n",
    "\n",
    "        X_transformed = pd.concat([cat_df, num_df], axis=1)\n",
    "        X_transformed.fillna(0, inplace=True)\n",
    "\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = (hotel_bookings_train_data['children'] == 0) & (hotel_bookings_train_data['adults'] == 0) & (hotel_bookings_train_data['babies'] == 0)\n",
    "df_filtered = hotel_bookings_train_data[~filter]\n",
    "X = df_filtered.drop('is_canceled', axis=1)\n",
    "y = df_filtered['is_canceled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['booking_id', 'hotel', 'lead_time', 'arrival_date_year',\n",
       "       'arrival_date_month', 'arrival_date_week_number',\n",
       "       'arrival_date_day_of_month', 'stays_in_weekend_nights',\n",
       "       'stays_in_week_nights', 'adults', 'children', 'babies', 'meal',\n",
       "       'country', 'market_segment', 'distribution_channel',\n",
       "       'is_repeated_guest', 'previous_cancellations',\n",
       "       'previous_bookings_not_canceled', 'reserved_room_type',\n",
       "       'assigned_room_type', 'booking_changes', 'deposit_type', 'agent',\n",
       "       'company', 'days_in_waiting_list', 'customer_type', 'adr',\n",
       "       'required_car_parking_spaces', 'total_of_special_requests',\n",
       "       'reservation_status', 'reservation_status_date', 'arrival_date',\n",
       "       'booking_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Simple Models First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying different models and defining the respective pipelines\n",
    "\n",
    "# shallow decision tree\n",
    "params_dt = {\n",
    "    'max_depth': 3,\n",
    "    'min_samples_split': 2\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(**params_dt)\n",
    "pipe_dt = Pipeline(steps=[\n",
    "    ('preprocessor', CustomPreprocessor()),\n",
    "    ('dt', dt)\n",
    "])\n",
    "\n",
    "# random forest\n",
    "params_rf = {\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(**params_rf)\n",
    "pipe_rf = Pipeline(steps=[\n",
    "    ('preprocessor', CustomPreprocessor()),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "# xgboost\n",
    "xgboost = xgb.XGBClassifier()\n",
    "pipe_xgb = Pipeline(steps=[\n",
    "    ('preprocessor', CustomPreprocessor()),\n",
    "    ('xgb', xgboost)\n",
    "])\n",
    "\n",
    "#adaboost\n",
    "adaboost = AdaBoostClassifier()\n",
    "pipe_ada = Pipeline(steps=[\n",
    "    ('preprocessor', CustomPreprocessor()),\n",
    "    ('ada', adaboost)\n",
    "])\n",
    "\n",
    "pipelines = [pipe_dt, pipe_rf, pipe_xgb, pipe_ada]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging the simple models in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID: 930259693027444821\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://localhost:9080\")\n",
    "experiment_name = \"baseline_models\"\n",
    "\n",
    "# Check if the experiment already exists, if not, create a new one\n",
    "try:\n",
    "    experiment_orig_id = mlflow.create_experiment(experiment_name)\n",
    "except mlflow.exceptions.MlflowException:\n",
    "    experiment_orig_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "# Print out the experiment ID for reference\n",
    "print(\"Experiment ID:\", experiment_orig_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs:/849e364a62594a62871073860736d048/model\n",
      "dt done\n",
      "======================\n",
      "\n",
      "runs:/f0fff373906d4025969ad4e7a46512ec/model\n",
      "rf done\n",
      "======================\n",
      "\n",
      "runs:/3d87a868dae44549bf4d0e928b88a9b4/model\n",
      "xgb done\n",
      "======================\n",
      "\n",
      "runs:/9922186b5a8d408b98d77b9f92d8c5fb/model\n",
      "ada done\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_infos = []\n",
    "\n",
    "for pipeline in pipelines:\n",
    "    with mlflow.start_run(experiment_id=experiment_orig_id, nested=True):\n",
    "        model_name = pipeline[-1].__class__.__name__\n",
    "        mlflow.log_param('model_name', model_name)\n",
    "        model_params = pipeline[-1].get_params()\n",
    "        metric_names = ['accuracy', 'f1', 'precision', 'recall']\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_train_pred = pipeline.predict(X_train)\n",
    "        y_test_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        train_report = classification_report(y_train, y_train_pred, output_dict=True)\n",
    "        training_metrics = {\n",
    "            'Accuracy': round(train_report['accuracy'], 3),\n",
    "            'F1': round(train_report['macro avg']['f1-score'], 3),\n",
    "            'Precision': round(train_report['macro avg']['precision'], 3),\n",
    "            'Recall': round(train_report['macro avg']['recall'], 3)\n",
    "        }\n",
    "        training_metrics_values = list(training_metrics.values())\n",
    "\n",
    "        test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "        testing_metrics = {\n",
    "            'Accuracy': round(test_report['accuracy'], 3),\n",
    "            'F1': round(test_report['macro avg']['f1-score'], 3),\n",
    "            'Precision': round(test_report['macro avg']['precision'], 3),\n",
    "            'Recall': round(test_report['macro avg']['recall'], 3)\n",
    "        }\n",
    "        testing_metrics_values = list(testing_metrics.values())\n",
    "    \n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            pipeline,\n",
    "            'model',\n",
    "            input_example=X_train \n",
    "        )\n",
    "\n",
    "        # Log each metric\n",
    "        for name, metric in list(zip(metric_names, training_metrics_values)):\n",
    "            mlflow.log_metric(f'training_{name}', metric)\n",
    "        for name, metric in list(zip(metric_names, testing_metrics_values)):\n",
    "            mlflow.log_metric(f'test_{name}', metric)\n",
    "        \n",
    "        # Log each hyper-parameter\n",
    "        for param_name, param_value in model_params.items():\n",
    "            mlflow.log_param(param_name, param_value)\n",
    "\n",
    "        print(model_info.model_uri)\n",
    "        run_infos.append(model_info.model_uri)\n",
    "        print(pipeline.steps[-1][0], 'done')\n",
    "        print('======================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.998\n",
      "Best model: xgb\n",
      "Best run_id: 3d87a868dae44549bf4d0e928b88a9b4\n"
     ]
    }
   ],
   "source": [
    "runs = mlflow.search_runs(experiment_ids=[experiment_orig_id])\n",
    "\n",
    "best_orig_f1_score = -float('inf')\n",
    "best_orig_model = None\n",
    "best_orig_model_params = None\n",
    "best_orig_run_id = None\n",
    "\n",
    "for index, run in runs.iterrows():\n",
    "    run_id = run[\"run_id\"]\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        model_uri = f\"runs:/{run_id}/model\"\n",
    "        model = mlflow.sklearn.load_model(model_uri)\n",
    "        metrics = mlflow.get_run(run_id=run_id).data.metrics\n",
    "        \n",
    "        if 'test_f1' in metrics:\n",
    "            run_f1_score = metrics['test_f1']\n",
    "            if run_f1_score > best_orig_f1_score:\n",
    "                best_orig_f1_score = run_f1_score\n",
    "                best_orig_model = model\n",
    "                best_orig_model_params = mlflow.get_run(run_id=run_id).data.params\n",
    "                best_orig_run_id = run_id\n",
    "\n",
    "print(\"Best F1 score:\", best_orig_f1_score)\n",
    "print(\"Best model:\", best_orig_model.steps[-1][0])\n",
    "# print(\"Best model parameters:\", best_orig_model_params)\n",
    "print(\"Best run_id:\", best_orig_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying finetuning the 4 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging the different model versions during finetuning in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID: 112110963367740946\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://localhost:9080\")\n",
    "experiment_name = \"finetuned_models\"\n",
    "\n",
    "# Check if the experiment already exists, if not, create a new one\n",
    "try:\n",
    "    experiment_id_finetune = mlflow.create_experiment(experiment_name)\n",
    "except mlflow.exceptions.MlflowException:\n",
    "    experiment_id_finetune = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "# Print out the experiment ID for reference\n",
    "print(\"Experiment ID:\", experiment_id_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs:/fbd2151618814892a05132ce8b36105d/model                                                                                        \n",
      "runs:/9407f1e00ccf4eae8ed1debf890c3402/model                                                                                        \n",
      "runs:/e309209dfefd445e81d5e561e712ee5e/model                                                                                        \n",
      "runs:/2c0d4f99e4064e43ae038af8e7dda9a6/model                                                                                        \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:19<00:00, 19.99s/trial, best loss: -0.778]\n",
      "dt done\n",
      "======================\n",
      "\n",
      "runs:/da65bd57e1d84943a04c778045e9981a/model                                                                                        \n",
      "runs:/63adecea7c964aa187d1f293f0f416c5/model                                                                                        \n",
      "runs:/4ead59814c4149a19d06b79af0b1d51e/model                                                                                        \n",
      "runs:/12ab6f610e9c48a6b7f7bc491a226cf6/model                                                                                        \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:02<00:00, 30.74s/trial, best loss: -0.92]\n",
      "rf done\n",
      "======================\n",
      "\n",
      "runs:/51333e8683b2476aaff272c5de660adc/model                                                                                        \n",
      "runs:/fe0c4df657ec45268f8f0c74660ce450/model                                                                                        \n",
      "runs:/ebea1f2d23c64714ac3b513117402039/model                                                                                        \n",
      "runs:/11f5adc937cd4da2b520ef241059c024/model                                                                                        \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:24<00:00, 21.16s/trial, best loss: -0.999]\n",
      "xgb done\n",
      "======================\n",
      "\n",
      "runs:/112f7ef079464686a140d2eb1ab80cac/model                                                                                        \n",
      "runs:/d763c26c417f4ea986e40ba2ac2b14d7/model                                                                                        \n",
      "runs:/904968c4a403406381e2b5908449ebb4/model                                                                                        \n",
      "runs:/6a4cbc982d224e8ba97fde9112e6d6a5/model                                                                                        \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:19<00:00, 34.78s/trial, best loss: -0.813]\n",
      "ada done\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_hyperopt_dt = {\n",
    "    'dt__max_depth': hp.choice('max_depth_dt', [3, 5, 7]),\n",
    "    'dt__min_samples_split': hp.choice('min_samples_split_dt', [2, 5, 10]),\n",
    "    'dt__min_samples_leaf': hp.choice('min_samples_leaf_dt', [1, 2, 4])\n",
    "}\n",
    "\n",
    "param_hyperopt_rf = {\n",
    "    'rf__n_estimators': hp.choice('n_estimators_rf', [50, 100, 200]),\n",
    "    'rf__max_depth': hp.choice('max_depth_rf', [None, 5, 10, 20]),\n",
    "    'rf__min_samples_split': hp.choice('min_samples_split_rf', [2, 5, 10]),\n",
    "    'rf__min_samples_leaf': hp.choice('min_samples_leaf_rf', [1, 2, 4])\n",
    "}\n",
    "\n",
    "param_hyperopt_xgb = {\n",
    "    'xgb__max_depth': hp.choice('max_depth_xgb', [3, 4, 5, 6]),\n",
    "    'xgb__learning_rate': hp.uniform('learning_rate_xgb', 0.01, 0.2),\n",
    "    'xgb__n_estimators': hp.choice('n_estimators_xgb', [100, 200, 300])\n",
    "}\n",
    "\n",
    "param_hyperopt_ada = {\n",
    "    'ada__n_estimators': hp.choice('n_estimators_ada', [50, 100, 200]),\n",
    "    'ada__learning_rate': hp.uniform('learning_rate_ada', 0.01, 1.0),\n",
    "    'ada__algorithm': hp.choice('algorithm_ada', ['SAMME', 'SAMME.R'])\n",
    "}\n",
    "\n",
    "pipeline_param_spaces = [\n",
    "    (pipe_dt, param_hyperopt_dt),\n",
    "    (pipe_rf, param_hyperopt_rf),\n",
    "    (pipe_xgb, param_hyperopt_xgb),\n",
    "    (pipe_ada, param_hyperopt_ada)\n",
    "]\n",
    "\n",
    "model_names = {\n",
    "    pipe_dt: 'Decision Tree',\n",
    "    pipe_rf: 'Random Forest',\n",
    "    pipe_xgb: 'XGBoost',\n",
    "    pipe_ada: 'AdaBoost'\n",
    "}\n",
    "\n",
    "best_params_list = []\n",
    "\n",
    "for pipeline, param_space in pipeline_param_spaces:\n",
    "\n",
    "    def train_model(params):\n",
    "        with mlflow.start_run(experiment_id=experiment_id_finetune, nested=True):\n",
    "            model_name = pipeline[-1].__class__.__name__\n",
    "            mlflow.log_param('model_name', model_name)\n",
    "            metric_names = ['accuracy', 'f1', 'precision', 'recall']\n",
    "            clf = pipeline.set_params(**params)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_train_pred = clf.predict(X_train)\n",
    "            y_test_pred = clf.predict(X_test)\n",
    "            \n",
    "            train_report = classification_report(y_train, y_train_pred, output_dict=True)\n",
    "            training_metrics = {\n",
    "                'Accuracy': round(train_report['accuracy'], 3),\n",
    "                'F1': round(train_report['macro avg']['f1-score'], 3),\n",
    "                'Precision': round(train_report['macro avg']['precision'], 3),\n",
    "                'Recall': round(train_report['macro avg']['recall'], 3)\n",
    "            }\n",
    "            training_metrics_values = list(training_metrics.values())\n",
    "    \n",
    "            test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "            testing_metrics = {\n",
    "                'Accuracy': round(test_report['accuracy'], 3),\n",
    "                'F1': round(test_report['macro avg']['f1-score'], 3),\n",
    "                'Precision': round(test_report['macro avg']['precision'], 3),\n",
    "                'Recall': round(test_report['macro avg']['recall'], 3)\n",
    "            }\n",
    "            testing_metrics_values = list(testing_metrics.values())\n",
    "        \n",
    "            model_info = mlflow.sklearn.log_model(\n",
    "                clf,\n",
    "                'model',\n",
    "                input_example=X_train \n",
    "            )\n",
    "            \n",
    "            # Log each metric\n",
    "            for name, metric in list(zip(metric_names, training_metrics_values)):\n",
    "                mlflow.log_metric(f'training_{name}', metric)\n",
    "            for name, metric in list(zip(metric_names, testing_metrics_values)):\n",
    "                mlflow.log_metric(f'test_{name}', metric)\n",
    "            \n",
    "            # Log each hyper-parameter\n",
    "            hyparams_list = list(param_space.keys())\n",
    "            for name in hyparams_list:\n",
    "                mlflow.log_param(name, params[name])\n",
    "\n",
    "            print(model_info.model_uri)\n",
    "                \n",
    "            # Set the loss to -1*F1 so fmin maximizes the it\n",
    "            return {'loss': -1*testing_metrics['F1'], 'status': STATUS_OK}\n",
    "    \n",
    "    # Perform hyperparameter optimization using the TPE algorithm\n",
    "    trials = Trials()\n",
    "    best_params = fmin(\n",
    "        fn=train_model,\n",
    "        space=param_space,\n",
    "        algo=tpe.suggest,\n",
    "        trials=trials,\n",
    "        max_evals=4\n",
    "    )\n",
    "\n",
    "    print(pipeline.steps[-1][0], 'done')\n",
    "    print('======================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.999\n",
      "Best model: xgb\n",
      "Best model parameters: {'model_name': 'XGBClassifier', 'xgb__learning_rate': '0.13721342154766397', 'xgb__max_depth': '6', 'xgb__n_estimators': '300'}\n",
      "Best run_id: fe0c4df657ec45268f8f0c74660ce450\n"
     ]
    }
   ],
   "source": [
    "runs = mlflow.search_runs(experiment_ids=[experiment_id_finetune])\n",
    "\n",
    "best_finetune_f1_score = -float('inf')\n",
    "best_finetune_model = None\n",
    "best_finetune_model_params = None\n",
    "best_finetune_run_id = None\n",
    "\n",
    "for index, run in runs.iterrows():\n",
    "    run_id = run[\"run_id\"]\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        model_uri = f\"runs:/{run_id}/model\"\n",
    "        model = mlflow.sklearn.load_model(model_uri)\n",
    "        metrics = mlflow.get_run(run_id=run_id).data.metrics\n",
    "        \n",
    "        if 'test_f1' in metrics:\n",
    "            run_f1_score = metrics['test_f1']\n",
    "            if run_f1_score > best_finetune_f1_score:\n",
    "                best_finetune_f1_score = run_f1_score\n",
    "                best_finetune_model = model\n",
    "                best_finetune_model_params = mlflow.get_run(run_id=run_id).data.params\n",
    "                best_finetune_run_id = run_id\n",
    "\n",
    "print(\"Best F1 score:\", best_finetune_f1_score)\n",
    "print(\"Best model:\", best_finetune_model.steps[-1][0])\n",
    "print(\"Best model parameters:\", best_finetune_model_params)\n",
    "print(\"Best run_id:\", best_finetune_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_finetune_f1_score > best_orig_f1_score:\n",
    "    best_experiment_id = experiment_id_finetune\n",
    "    best_run_id = best_finetune_run_id\n",
    "\n",
    "else:\n",
    "    best_experiment_id = experiment_orig_id\n",
    "    best_run_id = best_orig_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model artifacts saved in the 'C:\\Users\\sidha\\Documents\\Stuff\\NUS\\Sem 2\\BT4301 Biz Dev and Deployment\\Group Project\\ml_model\\best_model_split' folder.\n"
     ]
    }
   ],
   "source": [
    "best_runs = mlflow.search_runs(experiment_ids=[best_experiment_id])\n",
    "for index, run in best_runs.iterrows():\n",
    "    run_id = run[\"run_id\"]\n",
    "    if run_id == best_run_id:\n",
    "        best_model_uri = f\"runs:/{run_id}/model\"\n",
    "        best_model = mlflow.sklearn.load_model(model_uri)\n",
    "        break\n",
    "\n",
    "best_model_folder = \"best_model_split\"\n",
    "os.makedirs(best_model_folder, exist_ok=True)\n",
    "mlflow.sklearn.save_model(best_model, best_model_folder)\n",
    "\n",
    "dst_folder = os.path.join(best_model_folder, \"model\")\n",
    "shutil.copytree(best_model_folder, dst_folder)\n",
    "\n",
    "print(\"Best model artifacts saved in the '{}\\\\best_model_split' folder.\".format(os.getcwd()))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
